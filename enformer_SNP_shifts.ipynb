{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7687e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from Bio.Seq import Seq\n",
    "from datasets import load_dataset\n",
    "from gpn.data import Genome, load_dataset_from_file_or_dir\n",
    "import grelu.resources\n",
    "from grelu.sequence.format import strings_to_one_hot\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "class VEPModel(torch.nn.Module):\n",
    "\tdef __init__(self, model, personalized_enformer=False, personalized_enformer_diff=False, shifts=[0]):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.model = model\n",
    "\t\tself.shifts = shifts\n",
    "\t\tself.personalized_enformer = personalized_enformer\n",
    "\t\tself.personalized_enformer_diff = personalized_enformer_diff\n",
    "\n",
    "\tdef get_personalized_enformer_diff_scores(self, x_ref, x_alt):\n",
    "\t\tx_ref = x_ref.permute(0, 2, 1)\n",
    "\t\tx_alt = x_alt.permute(0, 2, 1)\n",
    "\t\tseq1 = torch.cat([x_ref.unsqueeze(1), x_ref.unsqueeze(1)], dim=1)\n",
    "\t\tseq2 = torch.cat([x_alt.unsqueeze(1), x_alt.unsqueeze(1)], dim=1)\n",
    "\t\tbatch = {\"seq1\":seq1, \"seq2\":seq2}\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\toutputs = self.model.predict_step(batch, batch_idx=0)\n",
    "\t\treturn outputs[\"Y_diff\"]\n",
    "\n",
    "\tdef get_personalized_enformer_scores(self, x_ref, x_alt):\n",
    "\t\tx_ref = x_ref.permute(0, 2, 1)\n",
    "\t\tx_alt = x_alt.permute(0, 2, 1)\n",
    "\n",
    "\t\toutputs_ref = self.model(x_ref, \n",
    "               return_base_predictions=True,\n",
    "\t\t\t   base_predictions_head=None)\n",
    "\t\toutputs_alt = self.model(x_alt, \n",
    "               return_base_predictions=True,\n",
    "\t\t\t   base_predictions_head=None)\n",
    "\t\ty_ref = torch.cat([outputs_ref['human'], outputs_ref['mouse']], dim=2)\n",
    "\t\tassert y_ref.shape[1:] == (896, 5313 + 1643), f\"y_ref.shape: {y_ref.shape}; outputs_ref['human'].shape: {outputs_ref['human'].shape}; outputs_ref['mouse'].shape: {outputs_ref['mouse'].shape}\"\n",
    "\t\ty_alt = torch.cat([outputs_alt['human'], outputs_alt['mouse']], dim=2)\n",
    "\t\tassert y_alt.shape[1:] == (896, 5313 + 1643), f\"y_alt.shape: {y_alt.shape}; outputs_alt['human'].shape: {outputs_alt['human'].shape}; outputs_alt['mouse'].shape: {outputs_alt['mouse'].shape}\"\n",
    "\t\tlfc = torch.log2(1 + y_alt) - torch.log2(1 + y_ref) # torch.Size([bs, 896, 5313 + 1643]) for human\n",
    "\t\tl2 = torch.linalg.norm(lfc, dim=1) # [bs, 5313 + 1643]\n",
    "\t\treturn l2\n",
    "\n",
    "\tdef get_scores(self, x_ref, x_alt):\n",
    "\t\ty_ref = self.model(x_ref)\n",
    "\t\ty_alt = self.model(x_alt)\n",
    "\t\tlfc = torch.log2(1 + y_alt) - torch.log2(1 + y_ref) # [bs, 5313, 896]\n",
    "\t\tl2 = torch.linalg.norm(lfc, dim=2) # [bs, 5313]\n",
    "\t\treturn l2\n",
    "\n",
    "\tdef shift(self, x, shift_size):\n",
    "\t\tif shift_size == 0:\n",
    "\t\t\treturn x\n",
    "\t\t\n",
    "\t\toriginal_shape = x.shape\n",
    "\t\tassert x.shape[1] == 4, f\"x.shape: {x.shape}\"\n",
    "\n",
    "\t\t# x is bs x 4 x seq_len torch.Size([bs, 4, 196608])\n",
    "\t\t# we want to shift x by shift_size adding padding to the left or right\n",
    "\n",
    "\t\tNs = torch.zeros(x.shape[0], 4, abs(shift_size), device=x.device, dtype=x.dtype)+0.25\n",
    "\t\tassert Ns.shape == (x.shape[0], 4, abs(shift_size)), f\"Ns.shape: {Ns.shape}, shift_size: {shift_size}, x.shape: {x.shape}\"\n",
    "\n",
    "\t\tif shift_size > 0:\n",
    "\t\t\t#0: torch.Size([4, 4, 196608])\n",
    "\t\t\t# 1: torch.Size([4, 4, 196611])\n",
    "\t\t\t# 2: torch.Size([4, 4, 3])\n",
    "\n",
    "\t\t\t# add padding to the left\n",
    "\t\t\t# print (\"0:\",x.shape)\n",
    "\t\t\tx = torch.cat([Ns, x], dim=2)\n",
    "\t\t\t# print (\"1:\",x.shape)\n",
    "\t\t\tx = x[:,:,:-shift_size]\n",
    "\t\t\t# print (\"2:\",x.shape, shift_size)\n",
    "\t\telse:\n",
    "\t\t\t# add padding to the right\n",
    "\t\t\t# print (\"0:\",x.shape)\n",
    "\t\t\tx = torch.cat([x, Ns], dim=2)\n",
    "\t\t\t# print (\"1:\",x.shape)\n",
    "\t\t\tx = x[:,:,-shift_size:]\n",
    "\t\t\t# print (\"2:\",x.shape, shift_size)\n",
    "\t\t\n",
    "\t\tassert x.shape == original_shape, f\"x.shape: {x.shape}, original_shape: {original_shape}, shift_size: {shift_size}\"\n",
    "\t\t# AssertionError: x.shape: torch.Size([4, 2, 196610]),\n",
    "\t\t# original_shape: torch.Size([4, 4, 196608])\n",
    "\n",
    "\t\tassert x.shape[1] == 4, f\"x.shape: {x.shape}\"\n",
    "\t\treturn x\n",
    "\n",
    "\tdef forward(\n",
    "\t\tself,\n",
    "\t\tx_ref_fwd=None,\n",
    "\t\tx_alt_fwd=None,\n",
    "\t\tx_ref_rev=None,\n",
    "\t\tx_alt_rev=None,\n",
    "\t):\n",
    "\t\tif self.personalized_enformer:\n",
    "\t\t\tscore_fn = self.get_personalized_enformer_scores\n",
    "\t\telif self.personalized_enformer_diff:\n",
    "\t\t\tscore_fn = self.get_personalized_enformer_diff_scores\n",
    "\t\telse:\n",
    "\t\t\tscore_fn = self.get_scores\n",
    "\n",
    "\t\tscores = []\n",
    "\t\tfor shift in self.shifts:\n",
    "\t\t\tscores.append(score_fn(self.shift(x_ref_fwd, shift), self.shift(x_alt_fwd, shift)))\n",
    "\t\t\tscores.append(score_fn(self.shift(x_ref_rev, shift), self.shift(x_alt_rev, shift)))\n",
    "\n",
    "\t\treturn torch.mean(torch.stack(scores), dim=0)\n",
    "\n",
    "\n",
    "def run_vep(\n",
    "\tvariants,\n",
    "\tgenome,\n",
    "\twindow_size,\n",
    "\tmodel,\n",
    "\tper_device_batch_size=8,\n",
    "\tdataloader_num_workers=0,\n",
    "):\n",
    "\tdef transform(V):\n",
    "\t\t# we convert from 1-based coordinate (standard in VCF) to\n",
    "\t\t# 0-based, to use with Genome\n",
    "\t\tchrom = np.array(V[\"chrom\"])\n",
    "\t\tn = len(chrom)\n",
    "\t\tpos = np.array(V[\"pos\"]) - 1\n",
    "\t\tstart = pos - window_size // 2\n",
    "\t\tend = pos + window_size // 2\n",
    "\t\tseq_fwd, seq_rev = zip(\n",
    "\t\t\t*(genome.get_seq_fwd_rev(chrom[i], start[i], end[i]) for i in range(n))\n",
    "\t\t)\n",
    "\t\tseq_fwd = np.array([list(seq.upper()) for seq in seq_fwd], dtype=\"object\")\n",
    "\t\tseq_rev = np.array([list(seq.upper()) for seq in seq_rev], dtype=\"object\")\n",
    "\t\tassert seq_fwd.shape[1] == window_size\n",
    "\t\tassert seq_rev.shape[1] == window_size\n",
    "\t\tref_fwd = np.array(V[\"ref\"])\n",
    "\t\talt_fwd = np.array(V[\"alt\"])\n",
    "\t\tref_rev = np.array([str(Seq(x).reverse_complement()) for x in ref_fwd])\n",
    "\t\talt_rev = np.array([str(Seq(x).reverse_complement()) for x in alt_fwd])\n",
    "\t\tpos_fwd = window_size // 2\n",
    "\t\tpos_rev = pos_fwd - 1 if window_size % 2 == 0 else pos_fwd\n",
    "\n",
    "\t\tdef prepare_output(seq, pos, ref, alt):\n",
    "\t\t\tassert (seq[:, pos] == ref).all(), f\"{seq[:, pos]}, {ref}\"\n",
    "\t\t\tseq_ref = seq\n",
    "\t\t\tseq_alt = seq.copy()\n",
    "\t\t\tseq_alt[:, pos] = alt\n",
    "\t\t\treturn (\n",
    "\t\t\t\tstrings_to_one_hot([\"\".join(x) for x in seq_ref]),\n",
    "\t\t\t\tstrings_to_one_hot([\"\".join(x) for x in seq_alt]),\n",
    "\t\t\t)\n",
    "\n",
    "\t\tres = {}\n",
    "\t\tres[\"x_ref_fwd\"], res[\"x_alt_fwd\"] = prepare_output(seq_fwd, pos_fwd, ref_fwd, alt_fwd)\n",
    "\t\tres[\"x_ref_rev\"], res[\"x_alt_rev\"] = prepare_output(seq_rev, pos_rev, ref_rev, alt_rev)\n",
    "\t\treturn res\n",
    "\n",
    "\tvariants.set_transform(transform)\n",
    "\ttraining_args = TrainingArguments(\n",
    "\t\toutput_dir=tempfile.TemporaryDirectory().name,\n",
    "\t\tper_device_eval_batch_size=per_device_batch_size,\n",
    "\t\tdataloader_num_workers=dataloader_num_workers,\n",
    "\t\tremove_unused_columns=False,\n",
    "\t\treport_to=\"none\",  # disables all reporting, including wandb\n",
    "\t)\n",
    "\ttrainer = Trainer(model=model, args=training_args)\n",
    "\treturn trainer.predict(test_dataset=variants).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a0c201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"complex_traits_matched_9\"\n",
    "if not os.path.exists(f\"results/dataset/{dataset}/test.parquet\"):\n",
    "\tos.makedirs(f\"results/dataset/{dataset}\", exist_ok=True)\n",
    "pd.read_parquet(f\"hf://datasets/songlab/TraitGym/{dataset}/test.parquet\").to_parquet(f\"results/dataset/{dataset}/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "951e3c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = Genome(\"results/genome.fa.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5c34f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = load_dataset_from_file_or_dir(\n",
    "\t\tf\"results/dataset/{dataset}/test.parquet\",\n",
    "\t\tsplit=\"test\",\n",
    "\t\tis_file=True,\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7682842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variants = variants.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ce2440c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/tgymMamba/lib/python3.10/site-packages/pytorch_lightning/utilities/migration/utils.py:49: PossibleUserWarning: The loaded checkpoint was produced with Lightning v2.5.0.post0, which is newer than your current Lightning version: v1.9.5\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "# model = grelu.resources.load_model(project=\"enformer\", model_name=\"human\")\n",
    "# instead:\n",
    "# download somewhere where wandb is no blocked\n",
    "# import wandb\n",
    "# api = wandb.Api()\n",
    "# art = api.artifact('grelu/enformer/human:latest')\n",
    "# art.download(\"C:\\\\Users\\\\user\\\\Downloads\\\\\")\n",
    "\n",
    "# then upload to /data/ckpts/wandb_human_enformer_latest.ckpt\n",
    "\n",
    "from grelu.lightning import LightningModel\n",
    "cpt_dir = \"data/ckpts/\"\n",
    "cpt_name = \"wandb_human_enformer_latest.ckpt\"\n",
    "model = LightningModel.load_from_checkpoint(os.path.join(cpt_dir, cpt_name), map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca7a8dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_output_path = \"results/metadata/Enformer.csv\"\n",
    "metadata = pd.DataFrame(model.data_params[\"tasks\"])\n",
    "if not os.path.exists(metadata_output_path):\n",
    "\tos.makedirs(os.path.dirname(metadata_output_path), exist_ok=True)\n",
    "\tmetadata.to_csv(metadata_output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42216401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = model.data_params['tasks'][\"name\"]\n",
    "window_size = model.data_params[\"train\"][\"seq_len\"]\n",
    "shifts = [-3,-6,0,3,6]\n",
    "model_full = VEPModel(model.model, shifts=shifts)\n",
    "\n",
    "per_device_batch_size = 4\n",
    "dataloader_num_workers = 16\n",
    "\n",
    "pred = run_vep(\n",
    "\tvariants,\n",
    "\tgenome,\n",
    "\twindow_size,\n",
    "\tmodel_full,\n",
    "\tper_device_batch_size=per_device_batch_size,\n",
    "\tdataloader_num_workers=dataloader_num_workers,\n",
    ")\n",
    "\n",
    "if len(shifts)>1:\n",
    "\tsave_model_name = f\"{cpt_name}-{len(shifts)}\"\n",
    "else:\n",
    "\tsave_model_name = cpt_name\n",
    "output_path = f\"results/dataset/{dataset}/features/{save_model_name}_L2.parquet\"\n",
    "\n",
    "directory = os.path.dirname(output_path)\n",
    "if directory != \"\" and not os.path.exists(directory):\n",
    "\tos.makedirs(directory)\n",
    "pd.DataFrame(pred, columns=columns).to_parquet(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d847061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENCFF833POA</th>\n",
       "      <th>ENCFF110QGM</th>\n",
       "      <th>ENCFF880MKD</th>\n",
       "      <th>ENCFF463ZLQ</th>\n",
       "      <th>ENCFF890OGQ</th>\n",
       "      <th>ENCFF996AEF</th>\n",
       "      <th>ENCFF660YSU</th>\n",
       "      <th>ENCFF787MSC</th>\n",
       "      <th>ENCFF568LMQ</th>\n",
       "      <th>ENCFF685MZL</th>\n",
       "      <th>...</th>\n",
       "      <th>CNhs14551</th>\n",
       "      <th>CNhs14618</th>\n",
       "      <th>CNhs14226</th>\n",
       "      <th>CNhs14229</th>\n",
       "      <th>CNhs14238</th>\n",
       "      <th>CNhs14239</th>\n",
       "      <th>CNhs14240</th>\n",
       "      <th>CNhs14241</th>\n",
       "      <th>CNhs14244</th>\n",
       "      <th>CNhs14245</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007151</td>\n",
       "      <td>0.007426</td>\n",
       "      <td>0.010048</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.006915</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.007520</td>\n",
       "      <td>0.009041</td>\n",
       "      <td>0.008568</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.002720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012779</td>\n",
       "      <td>0.011033</td>\n",
       "      <td>0.013261</td>\n",
       "      <td>0.008563</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.010085</td>\n",
       "      <td>0.008803</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.011925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009894</td>\n",
       "      <td>0.006118</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.004664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013707</td>\n",
       "      <td>0.014915</td>\n",
       "      <td>0.016609</td>\n",
       "      <td>0.013668</td>\n",
       "      <td>0.012713</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>0.014117</td>\n",
       "      <td>0.013406</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011026</td>\n",
       "      <td>0.006833</td>\n",
       "      <td>0.004081</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.006415</td>\n",
       "      <td>0.004842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042233</td>\n",
       "      <td>0.042491</td>\n",
       "      <td>0.050276</td>\n",
       "      <td>0.036298</td>\n",
       "      <td>0.047151</td>\n",
       "      <td>0.055230</td>\n",
       "      <td>0.030327</td>\n",
       "      <td>0.047163</td>\n",
       "      <td>0.043771</td>\n",
       "      <td>0.048341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030421</td>\n",
       "      <td>0.019885</td>\n",
       "      <td>0.010315</td>\n",
       "      <td>0.015707</td>\n",
       "      <td>0.012041</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>0.013122</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>0.020587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009971</td>\n",
       "      <td>0.016547</td>\n",
       "      <td>0.032334</td>\n",
       "      <td>0.007006</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.008690</td>\n",
       "      <td>0.007243</td>\n",
       "      <td>0.012781</td>\n",
       "      <td>0.008166</td>\n",
       "      <td>0.019799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030627</td>\n",
       "      <td>0.022836</td>\n",
       "      <td>0.007717</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.004725</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.021264</td>\n",
       "      <td>0.025121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5313 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENCFF833POA  ENCFF110QGM  ENCFF880MKD  ENCFF463ZLQ  ENCFF890OGQ  \\\n",
       "0     0.007151     0.007426     0.010048     0.005994     0.006915   \n",
       "1     0.012779     0.011033     0.013261     0.008563     0.009205   \n",
       "2     0.013707     0.014915     0.016609     0.013668     0.012713   \n",
       "3     0.042233     0.042491     0.050276     0.036298     0.047151   \n",
       "4     0.009971     0.016547     0.032334     0.007006     0.007911   \n",
       "\n",
       "   ENCFF996AEF  ENCFF660YSU  ENCFF787MSC  ENCFF568LMQ  ENCFF685MZL  ...  \\\n",
       "0     0.006616     0.007520     0.009041     0.008568     0.007695  ...   \n",
       "1     0.010085     0.008803     0.010515     0.009600     0.011925  ...   \n",
       "2     0.012658     0.011917     0.014117     0.013406     0.014505  ...   \n",
       "3     0.055230     0.030327     0.047163     0.043771     0.048341  ...   \n",
       "4     0.008690     0.007243     0.012781     0.008166     0.019799  ...   \n",
       "\n",
       "   CNhs14551  CNhs14618  CNhs14226  CNhs14229  CNhs14238  CNhs14239  \\\n",
       "0   0.006877   0.004066   0.001862   0.001971   0.001470   0.001695   \n",
       "1   0.009894   0.006118   0.003727   0.004223   0.002492   0.001939   \n",
       "2   0.011026   0.006833   0.004081   0.003441   0.002514   0.002845   \n",
       "3   0.030421   0.019885   0.010315   0.015707   0.012041   0.011184   \n",
       "4   0.030627   0.022836   0.007717   0.008418   0.006228   0.004725   \n",
       "\n",
       "   CNhs14240  CNhs14241  CNhs14244  CNhs14245  \n",
       "0   0.001498   0.001478   0.003121   0.002720  \n",
       "1   0.001603   0.002188   0.005033   0.004664  \n",
       "2   0.001811   0.002418   0.006415   0.004842  \n",
       "3   0.013122   0.014038   0.017381   0.020587  \n",
       "4   0.004778   0.006216   0.021264   0.025121  \n",
       "\n",
       "[5 rows x 5313 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df2 = pd.read_parquet(\"results/dataset/complex_traits_matched_9/features/wandb_human_enformer_latest.ckpt_L2.parquet\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f3c9266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_parquet(\"results/dataset/complex_traits_matched_9/features/wandb_human_enformer_latest.ckpt_L2.parquet\")\n",
    "df2 = pd.read_parquet(\"results/dataset/complex_traits_matched_9/features/wandb_human_enformer_latest.ckpt-5_L2.parquet\")\n",
    "(df2.columns.values == df1.columns.values).all()\n",
    "\n",
    "md1 = pd.read_csv(\"results/metadata/wandb_human_enformer_latest.ckpt.csv\")\n",
    "md2 = pd.read_csv(\"results/metadata/wandb_human_enformer_latest.ckpt-5.csv\")\n",
    "assert (md1.columns.values == md2.columns.values).all()\n",
    "assert (md1.index.values == md2.index.values).all()\n",
    "assert (md1[\"name\"].values == md2[\"name\"].values).all()\n",
    "assert (md1[\"assay\"].values == md2[\"assay\"].values).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f0375b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy metadata file\n",
    "metadata = pd.read_csv(\"results/metadata/Enformer_human.csv\")\n",
    "metadata.to_csv(f\"results/metadata/{save_model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31017f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11400, 5313)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape # (11400, 5313) - 11400 SNVs x 5313 enformer track predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81617505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calc stats:\n",
    "# snakemake -s workflow/Snakefile --cores 4 results/dataset/complex_traits_matched_9/AUPRC_by_chrom_weighted_average/all/Enformer_L2_L2.plus.all.csv\n",
    "\n",
    "# job                                     count\n",
    "# ------------------------------------  -------\n",
    "# dataset_subset_all                          1\n",
    "# get_metric_by_block                         1\n",
    "# get_metric_by_block_weighted_average        1\n",
    "# grelu_aggregate_assay                       1\n",
    "# unsupervised_pred                           1\n",
    "# total                                       5\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tgymMamba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
